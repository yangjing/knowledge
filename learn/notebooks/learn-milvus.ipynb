{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbf20cb",
   "metadata": {},
   "source": [
    "# 使用 Milvus 的 Qwen3 Embeddings 和 Rerankers 模型的 RAG 实践操作\n",
    "\n",
    "如果您一直在关注嵌入模型领域，您可能已经注意到阿里巴巴刚刚发布了 [Qwen3 嵌入系列](https://qwenlm.github.io/blog/qwen3-embedding/)。他们发布了嵌入模型和 Rerankers 模型，各有三种大小（0.6B、4B、8B），都是建立在 Qwen3 基础模型上，专门为检索任务设计的。\n",
    "\n",
    "我发现 Qwen3 系列有几个有趣的特点：\n",
    "\n",
    "- **多语言嵌入**--他们声称有一个跨 100 多种语言的统一语义空间\n",
    "- **指令提示**--您可以通过自定义指令来修改嵌入行为\n",
    "- **可变尺寸**--通过 Matryoshka 表征学习支持不同的嵌入尺寸\n",
    "- **32K 上下文长度**--可处理较长的输入序列\n",
    "- **标准的双编码器/交叉编码器设置**--嵌入模型使用双编码器，Reranker 使用交叉编码器\n",
    "\n",
    "从基准测试结果来看，Qwen3-Embedding-8B 在 MTEB 多语言排行榜上取得了 70.58 的高分，超过了 BGE、E5，甚至 Google Gemini。Qwen3-Reranker-8B 在多语言排名任务中创下了 69.02 的成绩。这不仅仅是 \"在开源模型中相当不错\"，而是全面超越了主流商业应用程序接口。在 RAG 检索、跨语言搜索和代码搜索系统中，尤其是在中文环境中，这些模型已经具备了生产就绪的能力。\n",
    "\n",
    "![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdZCKoPqf8mpxwQ_s-gGbdHYvw_HhWn6Ib62v8C_VEZF8AOSnY1yLEEv1ztkINpmwgHAVC5kZw6rWplfx5OkISf_gL4VvoqlXxSfs8s_qd8mdBuA0HBhP9kEdipXy0QVuPmEyOJRg?key=nqzZfIwgkzdlEZQ2MYSMGQ)\n",
    "\n",
    "![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdNppvBpn_5M9d6WDb0-pCjgTobVc9eFw_m6m6Vg73wJtB9OvcPFw5089FUui_N2-LbJVjJPe1c8_EnYY4F3Ryw0021kvmJ0jU0Q06qG2ZX2D1vywIyd5aKqO_cx-77U_spMVr8cQ?key=nqzZfIwgkzdlEZQ2MYSMGQ)\n",
    "\n",
    "作为一个可能已经使用过常见的模型（OpenAI 的 Embeddings、BGE、E5）的人，你可能想知道这些模型是否值得你花时间去研究。剧透：值得。\n",
    "\n",
    "## 我们正在构建什么\n",
    "\n",
    "本教程使用 Qwen3-Embedding-0.6B 和 Qwen3-Reranker-0.6B 以及 Milvus 来构建一个完整的 RAG 系统。我们将实施一个两阶段检索管道：\n",
    "\n",
    "1. 使用 Qwen3 Embeddings 进行密集检索，以快速选择候选对象\n",
    "2. 使用 Qwen3 交叉编码器进行重排，以提高精确度\n",
    "3. 使用 OpenAI 的 GPT-4 生成最终回复\n",
    "\n",
    "最后，您将拥有一个可处理多语言查询、使用指令提示进行领域调整，并通过智能 Rerankers 实现速度与精度平衡的工作系统。\n",
    "\n",
    "## 环境设置\n",
    "\n",
    "让我们从依赖项开始。请注意最低版本要求，这对兼容性很重要：\n",
    "\n",
    "```python\n",
    "pip install --upgrade pymilvus openai requests tqdm sentence-transformers transformers\n",
    "```\n",
    "\n",
    "_要求 transformers>=4.51.0 和 Sentence-transformers>=2.7.0_\n",
    "\n",
    "在本教程中，我们将使用 OpenAI 作为生成模型。设置您的 API 密钥：\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[“OPENAI_API_KEY”] = “sk-***********”\n",
    "```\n",
    "\n",
    "## 数据准备\n",
    "\n",
    "我们将使用 Milvus 文档作为知识库--它是技术内容的良好组合，可测试检索和生成质量。\n",
    "\n",
    "下载并提取文档：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58af65b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip -o ../runs/milvus_docs_2.4.x_en.zip\n",
    "# !unzip -q ../runs/milvus_docs_2.4.x_en.zip -d ../runs/milvus_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b66a74",
   "metadata": {},
   "source": [
    "加载标记符文件并对其进行分块。我们在此使用简单的基于标题的分块策略--对于生产系统，请考虑更复杂的分块方法：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd521965",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjing/workspaces/aiguide-python/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "from pymilvus import MilvusClient\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba043bb9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 设置环境变量解决 tokenizers 并行化警告\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "# 设置 huggingface 中国镜像\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041e2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import text lines is 4\n"
     ]
    }
   ],
   "source": [
    "text_lines = []\n",
    "\n",
    "for file_path in glob('../runs/milvus_docs/en/faq/*.md', recursive=True):\n",
    "  with open(file_path, 'r') as file:\n",
    "    file_text = file.read()\n",
    "    text_lines.append(file_text)\n",
    "\n",
    "print(f'Import text lines is {len(text_lines)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4957ae",
   "metadata": {},
   "source": [
    "## 模型设置\n",
    "\n",
    "现在来初始化我们的模型。我们使用的是轻量级的 0.6B 版本，它在性能和资源需求之间取得了很好的平衡：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_false_id: 2152\n",
      "token_true_id: 9693\n",
      "prefix_tokens: [151644, 8948, 198, 60256, 3425, 279, 11789, 20027, 279, 8502, 3118, 389, 279, 11361, 323, 279, 758, 1235, 3897, 13, 7036, 429, 279, 4226, 646, 1172, 387, 330, 9693, 1, 476, 330, 2152, 3263, 151645, 198, 151644, 872, 198]\n",
      "suffix_tokens: [151645, 198, 151644, 77091, 14621]\n"
     ]
    }
   ],
   "source": [
    "EMBED_MODEL_NAME = 'Qwen/Qwen3-Embedding-0.6B'\n",
    "RERANKER_MODEL_NAME = 'Qwen/Qwen3-Reranker-0.6B'\n",
    "\n",
    "# Load Qwen3-Embedding-0.6B model for text embeddings\n",
    "embedding_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
    "\n",
    "\n",
    "# Load Qwen3-Reranker-0.6B model for reranking\n",
    "reranker_tokenizer = AutoTokenizer.from_pretrained(RERANKER_MODEL_NAME, padding_side='left')\n",
    "reranker_model = AutoModelForCausalLM.from_pretrained(RERANKER_MODEL_NAME).eval()\n",
    "\n",
    "\n",
    "# Reranker configuration\n",
    "token_false_id = reranker_tokenizer.convert_tokens_to_ids('no')\n",
    "token_true_id = reranker_tokenizer.convert_tokens_to_ids('yes')\n",
    "max_reranker_length = 8192\n",
    "\n",
    "prefix = '<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \"yes\" or \"no\".<|im_end|>\\n<|im_start|>user\\n'\n",
    "suffix = '<|im_end|>\\n<|im_start|>assistant\\n\\n\\n\\n\\n'\n",
    "prefix_tokens = reranker_tokenizer.encode(prefix, add_special_tokens=False)\n",
    "suffix_tokens = reranker_tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "print(f'token_false_id: {token_false_id}')\n",
    "print(f'token_true_id: {token_true_id}')\n",
    "print(f'prefix_tokens: {prefix_tokens}')\n",
    "print(f'suffix_tokens: {suffix_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c660e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_text(text: str, is_query=False):\n",
    "  \"\"\"Generate text embeddings using Qwen3-Embedding-0.6B model\n",
    "\n",
    "  Args:\n",
    "    text: Input text to embed\n",
    "    is_query: Whether this is query (True) or document (False)\n",
    "\n",
    "  Returns:\n",
    "    List of embedding values\n",
    "  \"\"\"\n",
    "\n",
    "  if is_query:\n",
    "    embeddings = embedding_model.encode([text], prompt_name='query')\n",
    "  else:\n",
    "    embeddings = embedding_model.encode([text])\n",
    "\n",
    "  return embeddings[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53653f",
   "metadata": {},
   "source": [
    "让我们来测试嵌入功能并检查输出维度：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b8ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入维度: 1024\n",
      "头 10 个值 : [-0.013050967827439308, -0.07333958148956299, -0.010180089622735977, -0.056118570268154144, 0.031972434371709824, 0.04878552630543709, 0.01245422288775444, 0.04370049387216568, -0.0664646252989769, 0.0325627475976944]\n"
     ]
    }
   ],
   "source": [
    "test_embedding = emb_text('这是一个测试')\n",
    "embedding_dim = len(test_embedding)\n",
    "print(f'嵌入维度: {embedding_dim}')\n",
    "print(f'头 10 个值 : {test_embedding[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0bab6",
   "metadata": {},
   "source": [
    "## Reranker 实现\n",
    "\n",
    "Reranker 使用交叉编码器架构来评估查询-文档对。这比双编码器嵌入模型的计算成本更高，但能提供更细致的相关性评分。\n",
    "\n",
    "下面是完整的 Rerankers 流程：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(instruction, query, doc):\n",
    "  \"\"\"Format instruction for reranker input\"\"\"\n",
    "  if instruction is None:\n",
    "    instruction = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "  output = '<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}'.format(\n",
    "    instruction=instruction, query=query, doc=doc\n",
    "  )\n",
    "  return output\n",
    "\n",
    "\n",
    "def process_inputs(pairs):\n",
    "  \"\"\"Process inputs for reranker\"\"\"\n",
    "  tokenized = reranker_tokenizer(\n",
    "    pairs,\n",
    "    add_special_tokens=False,\n",
    "    truncation=True,\n",
    "    max_length=max_reranker_length - len(prefix_tokens) - len(suffix_tokens),\n",
    "  )\n",
    "\n",
    "  # Step 2: 拼接 prefix_tokens + token + suffix_tokens\n",
    "  input_ids = [prefix_tokens + ids + suffix_tokens for ids in tokenized['input_ids']]\n",
    "\n",
    "  # Step 3: 使用 tokenizer 的 pad 功能，一次性转为 tensor\n",
    "  padded = reranker_tokenizer.pad(\n",
    "    {'input_ids': input_ids}, padding=True, return_tensors='pt', max_length=max_reranker_length\n",
    "  )\n",
    "\n",
    "  return padded\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_logits(inputs):\n",
    "  \"\"\"Compute relevance scores using reranker\"\"\"\n",
    "  batch_scores = reranker_model(**inputs).logits[:, -1, :]\n",
    "  true_vector = batch_scores[:, token_true_id]\n",
    "  false_vector = batch_scores[:, token_false_id]\n",
    "  batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "  batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "  scores = batch_scores[:, 1].exp().tolist()\n",
    "  return scores\n",
    "\n",
    "\n",
    "def rerank_documents(query, documents, task_instruction=None):\n",
    "  \"\"\"Rerank documents based on query relevance using Qwen3-Reranker\n",
    "\n",
    "  Args:\n",
    "    query: Search query\n",
    "    documents: List of documents to rerank\n",
    "    task_instruction: Task instruction for reranking\n",
    "\n",
    "  Returns:\n",
    "    List of (document, score) tuples sorted by relevance score\"\"\"\n",
    "\n",
    "  if task_instruction is None:\n",
    "    task_instruction = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "    # Format inputs for reranker\n",
    "    pairs = [format_instruction(task_instruction, query, doc) for doc in documents]\n",
    "    # Process inputs for reranker\n",
    "    inputs = process_inputs(pairs)\n",
    "    scores = compute_logits(inputs)\n",
    "\n",
    "    # Combine documents with scores and sort by score (descending)\n",
    "    doc_scores = list(zip(documents, scores))\n",
    "    doc_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return doc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ee267",
   "metadata": {},
   "source": [
    "## 设置 Milvus 向量数据库\n",
    "\n",
    "现在让我们建立向量数据库。为了简单起见，我们使用 Milvus Lite，但同样的代码也适用于完整的 Milvus 部署：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7c951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjing/workspaces/aiguide-python/.venv/lib/python3.13/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "milvus_client = MilvusClient(uri='./milvus_demo.db')\n",
    "\n",
    "collection_name = 'my_rag_collection'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93699e",
   "metadata": {},
   "source": [
    "**部署选项：**\n",
    "\n",
    "- **本地文件（如./milvus.db ）**：使用 Milvus Lite，非常适合开发\n",
    "- **Docker/Kubernetes**：使用服务器 URI，如 http://localhost:19530 用于生产\n",
    "- **Zilliz Cloud**：使用云端点和 API 密钥管理服务\n",
    "\n",
    "清理任何现有的 Collections 并创建一个新的：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d33980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing collection if it exists\n",
    "if milvus_client.has_collection(collection_name):\n",
    "  milvus_client.drop_collection(collection_name)\n",
    "# Create new collection with our embedding dimensions\n",
    "milvus_client.create_collection(\n",
    "  collection_name=collection_name,\n",
    "  dimension=embedding_dim,  # 1024 for Qwen3-Embedding-0.6B\n",
    "  metric_type='IP',  # Inner product for similarity\n",
    "  consistency_level='Strong',  # Ensure data consistency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e11100",
   "metadata": {},
   "source": [
    "## 将数据加载到 Milvus 中\n",
    "\n",
    "现在让我们处理我们的文档并将其插入向量数据库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7fdac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'insert_count': 4, 'ids': [0, 1, 2, 3], 'cost': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i, line in enumerate(tqdm(text_lines, desc='Creating embeddings')):\n",
    "  data.append({'id': i, 'vector': emb_text(line), 'text': line})\n",
    "\n",
    "milvus_client.insert(collection_name=collection_name, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725c39f",
   "metadata": {},
   "source": [
    "## 利用 Rerankers 技术增强 RAG\n",
    "\n",
    "现在到了激动人心的部分--将这一切整合到一个完整的检索增强生成系统中。\n",
    "\n",
    "### 步骤 1：查询和初始检索\n",
    "\n",
    "让我们用一个关于 Milvus 的常见问题进行测试：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "773fa823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 initial candidates\n"
     ]
    }
   ],
   "source": [
    "question = 'How is data stored in milvus?'\n",
    "\n",
    "# Perform initial dense retrieval to get top candidates\n",
    "search_res = milvus_client.search(\n",
    "  collection_name=collection_name,\n",
    "  data=[emb_text(question, is_query=True)],  # Use query prompt\n",
    "  limit=10,  # Get top 10 candidates for reranking\n",
    "  search_params={'metric_type': 'IP', 'params': {}},\n",
    "  output_fields=['text'],  # Return the actual text content\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Found {len(search_res[0])} initial candidates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bc9b003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KeysView({'id': 3, 'distance': 0.7633353471755981}),\n",
       " KeysView({'id': 0, 'distance': 0.6970409154891968}),\n",
       " KeysView({'id': 2, 'distance': 0.5539933443069458}),\n",
       " KeysView({'id': 1, 'distance': 0.5401155948638916, 'entity': {'text': '---\\nid: troubleshooting.md\\nsummary: Learn about common issues you may encounter with Milvus and how to overcome them.\\ntitle: Troubleshooting\\n---\\n# Troubleshooting\\nThis page lists common issues that may occur when running Milvus, as well as possible troubleshooting tips. Issues on this page fall into the following categories:\\n\\n- [Boot issues](#boot_issues)\\n- [Runtime issues](#runtime_issues)\\n- [API issues](#api_issues)\\n- [etcd crash issues](#etcd_crash_issues)\\n\\n\\n  ## Boot issues\\n\\n  Boot errors are usually fatal. Run the following command to view error details:\\n\\n  ```\\n  $ docker logs <your milvus container id>\\n  ```\\n\\n\\n  ## Runtime issues\\n\\n  Errors that occur during runtime may cause service breakdown. To troubleshoot this issue, check compatibility between the server and your client before moving forward.\\n\\n\\n  ## API issues\\n\\n  These issues occur during API method calls between the Milvus server and your client. They will be returned to the client synchronously or asynchronously.\\n  \\n\\n  ## etcd crash issues\\n  \\n  ### 1. etcd pod pending\\n\\n  The etcd cluster uses pvc by default. StorageClass needs to be preconfigured for the Kubernetes cluster.\\n\\n  ### 2. etcd pod crash\\n\\n  When an etcd pod crashes with `Error: bad member ID arg (strconv.ParseUint: parsing \"\": invalid syntax), expecting ID in Hex`, you can log into this pod and delete the `/bitnami/etcd/data/member_id` file.\\n\\n  ### 3. Multiple pods keep crashing while `etcd-0` is still running\\n\\n  You can run the following code if multiple pods keeps crashing while `etcd-0` is still running.\\n  \\n  ```\\n  kubectl scale sts <etcd-sts> --replicas=1\\n  # delete the pvc for etcd-1 and etcd-2\\n  kubectl scale sts <etcd-sts> --replicas=3\\n  ```\\n  \\n  ### 4. All pods crash\\n  \\n  When all pods crash, try copying the `/bitnami/etcd/data/member/snap/db` file. Use `https://github.com/etcd-io/bbolt` to modify database data.\\n\\n  All Milvus metadata are kept in the `key` bucket. Back up the data in this bucket and run the following commands. Note that the prefix data in the `by-dev/meta/session` file does not require a backup.\\n  \\n  ```\\n  kubectl kubectl scale sts <etcd-sts> --replicas=0\\n  # delete the pvc for etcd-0, etcd-1, etcd-2\\n  kubectl kubectl scale sts <etcd-sts> --replicas=1\\n  # restore the backup data\\n  ```\\n\\n\\n\\n<br/>\\n\\n  If you need help solving a problem, feel free to:\\n\\n  - Join our [Slack channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) and reach out for support from the Milvus team.\\n  - [File an Issue](https://github.com/milvus-io/milvus/issues/new/choose) on GitHub that includes details about your problem.\\n\\n'}})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[entry.keys() for entry in search_res[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccefcb",
   "metadata": {},
   "source": [
    "### 步骤 2：重排序以提高精确度\n",
    "\n",
    "提取候选文档并应用 Rerankers：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8757cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking documents……\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjing/workspaces/aiguide-python/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 3 documents after reranking\n"
     ]
    }
   ],
   "source": [
    "# Extract candidate documents\n",
    "candidate_docs = [res['entity']['text'] for res in search_res[0]]\n",
    "\n",
    "# Rerank using Qwen3-Reranker\n",
    "print('Reranking documents……')\n",
    "reranked_docs = rerank_documents(question, candidate_docs)\n",
    "\n",
    "\n",
    "# Select top 3 after reranking\n",
    "top_reranked_docs = reranked_docs[:3]\n",
    "print(f'Selected top {len(top_reranked_docs)} documents after reranking')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c75ad",
   "metadata": {},
   "source": [
    "### 步骤 3：比较结果\n",
    "\n",
    "让我们来看看 Rerankers 如何改变结果：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448a94a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked results (top 3):\n",
      "[\n",
      "  [\n",
      "    \"---\\nid: operational_faq.md\\nsummary: Find answers to commonly asked questions about operations in Milvus.\\ntitle: Operational FAQ\\n---\\n\\n# Operational FAQ\\n\\n<!-- TOC -->\\n\\n\\n<!-- /TOC -->\\n\\n#### What if I failed to pull the Milvus Docker image from Docker Hub?\\n\\nIf you failed to pull the Milvus Docker image from Docker Hub, try adding other registry mirrors. \\n\\nUsers from Mainland China can add the URL \\\"https://registry.docker-cn.com\\\" to the registry-mirrors array in **/etc.docker/daemon.json**.\\n\\n```\\n{\\n  \\\"registry-mirrors\\\": [\\\"https://registry.docker-cn.com\\\"]\\n}\\n```\\n\\n#### Is Docker the only way to install and run Milvus?\\n\\nDocker is an efficient way to deploy Milvus, but not the only way. You can also deploy Milvus from source code. This requires Ubuntu (18.04 or higher) or CentOS (7 or higher). See [Building Milvus from Source Code](https://github.com/milvus-io/milvus#build-milvus-from-source-code) for more information.\\n\\n#### What are the main factors affecting recall?\\n\\nRecall is affected mainly by index type and search parameters.\\n\\nFor FLAT index, Milvus takes an exhaustive scan within a collection, with a 100% return.\\n\\nFor IVF indexes, the nprobe parameter determines the scope of a search within the collection. Increasing nprobe increases the proportion of vectors searched and recall, but diminishes query performance.\\n\\nFor HNSW index, the ef parameter determines the breadth of the graph search. Increasing ef increases the number of points searched on the graph and recall, but diminishes query performance.\\n\\nFor more information, see [Vector Indexing](https://www.zilliz.com/blog/Accelerating-Similarity-Search-on-Really-Big-Data-with-Vector-Indexing).\\n\\n#### Why did my changes to the configuration files not take effect?\\n\\nMilvus does not support modification to configuration files during runtime. You must restart Milvus Docker for configuration file changes to take effect.\\n\\n#### How do I know if Milvus has started successfully?\\n\\nIf Milvus is started using Docker Compose, run `docker ps` to observe how many Docker containers are running and check if Milvus services started correctly.\\n\\nFor Milvus standalone, you should be able to observe at least three running Docker containers, one being the Milvus service and the other two being etcd management and storage service. For more information, see [Installing Milvus Standalone](install_standalone-docker.md).\\n\\n#### Why is the time in the log files different from the system time?\\n\\nThe time difference is usually due to the fact that the host machine does not use Coordinated Universal Time (UTC).\\n\\nThe log files inside the Docker image use UTC by default. If your host machine does not use UTC, this issue may occur.\\n\\n\\n#### How do I know if my CPU supports Milvus?\\n\\n{{fragments/cpu_support.md}}\\n\\n#### Why does Milvus return `illegal instruction` during startup?\\n\\nMilvus requires your CPU to support a SIMD instruction set: SSE4.2, AVX, AVX2, or AVX512. CPU must support at least one of these to ensure that Milvus operates normally. An `illegal instruction` error returned during startup suggests that your CPU does not support any of the above four instruction sets.\\n\\nSee [CPU’s support for SIMD Instruction Set](prerequisite-docker.md).\\n\\n#### Can I install Milvus on Windows?\\n\\nYes. You can install Milvus on Windows either by compiling from source code or from a binary package. \\n\\nSee [Run Milvus on Windows](https://milvus.io/blog/2021-11-19-run-milvus-2.0-on-windows.md) to learn how to install Milvus on Windows.\\n\\n#### I got an error when installing pymilvus on Windows. What shall I do?\\n\\nIt is not recommended to install PyMilvus on Windows. But if you have to install PyMilvus on Windows but got an error, try installing it in a [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html) environment. See [Install Milvus SDK](install-pymilvus.md) for more information about how to install PyMilvus in the Conda environment.\\n\\n#### Can I deploy Milvus when disconnected from the Internet?\\n\\nYes. You can install Milvus in an offline environment. See [Install Milvus Offline](install_offline-helm.md) for more information.\\n\\n#### Where can I find the logs generated by Milvus?\\n\\nThe Milvus log is printed to stout (standard output) and stderr (standard error) by default, however we highly recommend redirecting your log to a persistent volume in production. To do so, update `log.file.rootPath` in **milvus.yaml**. And if you deploy Milvus with `milvus-helm` chart, you also need to enable log persistence first via `--set log.persistence.enabled=true`. \\n\\nIf you didn't change the config, using kubectl logs <pod-name> or docker logs CONTAINER can also help you to find the log.\\n\\n\\n#### Can I create index for a segment before inserting data into it?\\n\\nYes, you can. But we recommend inserting data in batches, each of which should not exceed 256 MB, before indexing each segment.\\n\\n#### Can I share an etcd instance among multiple Milvus instances?\\n\\nYes, you can share an etcd instance among multiple Milvus instances. To do so, you need to change `etcd.rootPath` to a separate value for each Milvus instance in the configuration files of each before starting them.\\n\\n#### Can I share a Pulsar instance among multiple Milvus instances?\\n\\nYes, you can share a Pulsar instance among multiple Milvus instances. To do so, you can\\n\\n- If multi-tenancy is enabled on your Pulsar instance, consider allocating a separate tenant or namespace for each Milvus instance. To do so, you need to change `pulsar.tenant` or `pulsar.namespace` in the configuration files of your Milvus instances to a unique value for each before starting them.\\n- If you do not plan on enabling multi-tenancy on your Pulsar instance, consider changing `msgChannel.chanNamePrefix.cluster` in the configuration files of your Milvus instances to a unique value for each before starting them.\\n\\n#### Can I share a MinIO instance among multiple Milvus instances?\\n\\nYes, you can share a MinIO instance among multiple Milvus instances. To do so, you need to change `minio.rootPath` to a unique value for each Milvus instance in the configuration files of each before starting them.\\n\\n#### Still have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. Feel free to ask questions, share ideas, and help others.\\n- Join our [Milvus Forum](https://discuss.milvus.io/) or [Slack Channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.\\n\",\n",
      "    0.973656177520752\n",
      "  ],\n",
      "  [\n",
      "    \"---\\nid: performance_faq.md\\nsummary: Find answers to frequently asked questions about search performance, performance enhancements, and other performance related issues.\\ntitle: Performance FAQ\\n---\\n\\n# Performance FAQ\\n\\n<!-- TOC -->\\n\\n\\n<!-- /TOC -->\\n\\n#### How to set `nlist` and `nprobe` for IVF indexes?\\n\\nSetting `nlist` is scenario-specific. As a rule of thumb, the recommended value of `nlist` is `4 × sqrt(n)`, where `n` is the total number of entities in a segment.\\n\\nThe size of each segment is determined by the `datacoord.segment.maxSize` parameter, which is set to 512 MB by default. The total number of entities in a segment n can be estimated by dividing `datacoord.segment.maxSize` by the size of each entity.\\n\\nSetting `nprobe` is specific to the dataset and scenario, and involves a trade-off between accuracy and query performance. We recommend finding the ideal value through repeated experimentation.\\n\\nThe following charts are results from a test running on the sift50m dataset and IVF_SQ8 index, which compares recall and query performance of different `nlist`/`nprobe` pairs.\\n\\n![Accuracy test](../../../assets/accuracy_nlist_nprobe.png \\\"Accuracy test.\\\")\\n![Performance test](../../../assets/performance_nlist_nprobe.png \\\"Performance test.\\\")\\n\\n#### Why do queries sometimes take longer on smaller datasets?\\n\\nQuery operations are conducted on segments. indexes reduce the amount of time it takes to query a segment. If a segment has not been indexed, Milvus resorts to brute-force search on the raw data—drastically increasing query time.\\n\\nTherefore, it usually takes longer to query on a small dataset (collection) because it has not built index. This is because the sizes of its segments have not reached the index-building threshold set by `rootCoord.minSegmentSizeToEnableindex`. Call `create_index()` to force Milvus to index segments that have reached the threshold but not yet been automatically indexed, significantly improving query performance.\\n\\n\\n#### What factors impact CPU usage?\\n\\nCPU usage increases when Milvus is building indexes or running queries. In general, index building is CPU intensive except when using Annoy, which runs on a single thread.\\n\\nWhen running queries, CPU usage is affected by `nq` and `nprobe`. When `nq` and `nprobe` are small, concurrency is low and CPU usage stays low.\\n\\n#### Does simultaneously inserting data and searching impact query performance?\\n\\nInsert operations are not CPU intensive. However, because new segments may not have reached the threshold for index building, Milvus resorts to brute-force search—significantly impacting query performance.\\n\\nThe `rootcoord.minSegmentSizeToEnableIndex` parameter determines the index-building threshold for a segment, and is set to 1024 rows by default. See [System Configuration](system_configuration.md) for more information.\\n\\n#### Still have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. Feel free to ask questions, share ideas, and help others.\\n- Join our [Slack Channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.\\n\",\n",
      "    0.9111157655715942\n",
      "  ],\n",
      "  [\n",
      "    \"---\\nid: product_faq.md\\nsummary: Find answers to frequently asked questions about the world's most advanced vector database.\\ntitle: Product FAQ\\n---\\n\\n# Product FAQ\\n\\n<!-- TOC -->\\n\\n\\n\\n<!-- /TOC -->\\n\\n#### How much does Milvus cost?\\n\\nMilvus is a 100% free open-source project.\\n\\nPlease adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.\\n\\nZilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.\\n\\n#### Does Milvus support non-x86 architectures?\\n\\nMilvus cannot be installed or run on non-x86 platforms.\\n\\nYour CPU must support one of the following instruction sets to run Milvus: SSE4.2, AVX, AVX2, AVX512. These are all x86-dedicated SIMD instruction sets.\\n\\n#### What is the maximum dataset size Milvus can handle?\\n\\n  \\nTheoretically, the maximum dataset size Milvus can handle is determined by the hardware it is run on, specifically system memory and storage:\\n\\n- Milvus loads all specified collections and partitions into memory before running queries. Therefore, memory size determines the maximum amount of data Milvus can query.\\n- When new entities and and collection-related schema (currently only MinIO is supported for data persistence) are added to Milvus, system storage determines the maximum allowable size of inserted data.\\n\\n####  Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n#### Why is there no vector data in etcd?\\n\\netcd stores Milvus module metadata; MinIO stores entities.\\n\\n#### Does Milvus support inserting and searching data simultaneously?\\n\\nYes. Insert operations and query operations are handled by two separate modules that are mutually independent. From the client’s perspective, an insert operation is complete when the inserted data enters the message queue. However, inserted data are unsearchable until they are loaded to the query node. If the segment size does not reach the index-building threshold (512 MB by default), Milvus resorts to brute-force search and query performance may be diminished.\\n\\n#### Can vectors with duplicate primary keys be inserted into Milvus?\\n\\nYes. Milvus does not check if vector primary keys are duplicates.\\n\\n#### When vectors with duplicate primary keys are inserted, does Milvus treat it as an update operation?\\n\\nNo. Milvus does not currently support update operations and does not check if entity primary keys are duplicates. You are responsible for ensuring entity primary keys are unique, and if they aren't Milvus may contain multiple entities with duplicate primary keys.\\n\\nIf this occurs, which data copy will return when queried remains an unknown behavior. This limitation will be fixed in future releases.\\n\\n#### What is the maximum length of self-defined entity primary keys?\\n\\nEntity primary keys must be non-negative 64-bit integers.\\n\\n#### What is the maximum amount of data that can be added per insert operation?\\n\\nAn insert operation must not exceed 1,024 MB in size. This is a limit imposed by gRPC.\\n\\n#### Does collection size impact query performance when searching in a specific partition?\\n\\nNo. If partitions for a search are specified, Milvus searches the specified partitions only.\\n\\n#### Does Milvus load the entire collection when partitions are specified for a search?\\n\\nNo. Milvus has varied behavior. Data must be loaded to memory before searching.\\n\\n- If you know which partitions your data are located in, call `load_partition()` to load the intended partition(s) *then* specify partition(s) in the `search()` method call.\\n- If you do not know the exact partitions, call `load_collection()` before calling `search()`.\\n- If you fail to load collections or partitions before searching, Milvus returns an error.\\n\\n#### Can indexes be created after inserting vectors?\\n\\nYes. If an index has been built for a collection by `create_index()` before, Milvus will automatically build an index for subsequently inserted vectors. However, Milvus does not build an index until the newly inserted vectors fill an entire segment and the newly created index file is separate from the previous one.\\n\\n#### How are the FLAT and IVF_FLAT indexes different?\\n\\nThe IVF_FLAT index divides vector space into list clusters. At the default list value of 16,384, Milvus compares the distances between the target vector and the centroids of all 16,384 clusters to return probe nearest clusters. Milvus then compares the distances between the target vector and the vectors in the selected clusters to get the nearest vectors. Unlike IVF_FLAT, FLAT directly compares the distances between the target vector and every other vector.\\n\\nWhen the total number of vectors approximately equals nlist, there is little distance between IVF_FLAT and FLAT in terms of calculation requirements and search performance. However, as the number of vectors exceeds nlist by a factor of two or more, IVF_FLAT begins to demonstrate performance advantages.\\n\\nSee [Vector Index](index.md) for more information.\\n\\n#### How does Milvus flush data?\\n\\nMilvus returns success when inserted data are loaded to the message queue. However, the data are not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.\\n\\n#### What is normalization? Why is normalization needed?\\n\\nNormalization refers to the process of converting a vector so that its norm equals 1. If inner product is used to calculate vector similarity, vectors must be normalized. After normalization, inner product equals cosine similarity.\\n\\nSee [Wikipedia](https://en.wikipedia.org/wiki/Unit_vector) for more information.\\n\\n#### Why do Euclidean distance (L2) and inner product (IP) return different results?\\n\\nFor normalized vectors, Euclidean distance (L2) is mathematically equivalent to inner product (IP). If these similarity metrics return different results, check to see if your vectors are normalized\\n\\n#### Is there a limit to the total number of collections and partitions in Milvus?\\n\\nYes. You can create up to 65,535 collections in a Milvus instance. When calculating the number of existing collections, Milvus counts all collections with shards and partitions in them.\\n\\nFor example, let's assume you have already created 100 collections, with 2 shards and 4 partitions in 60 of them and with 1 shard and 12 partitions in the rest 40 collections. The current number of collections can be calculated as:\\n\\n```\\n60 * 2 * 4 + 40 * 1 * 12 = 960\\n```\\n\\n#### Why do I get fewer than k vectors when searching for `topk` vectors?\\n\\nAmong the indexes that Milvus supports, IVF_FLAT and IVF_SQ8 implement the k-means clustering method. A data space is divided into `nlist` clusters and the inserted vectors are distributed to these clusters. Milvus then selects the `nprobe` nearest clusters and compares the distances between the target vector and all vectors in the selected clusters to return the final results.\\n\\nIf `nlist` and `topk` are large and nprobe is small, the number of vectors in the nprobe clusters may be less than `k`. Therefore, when you search for the `topk` nearest vectors, the number of returned vectors is less than `k`.\\n\\nTo avoid this, try setting `nprobe` larger and `nlist` and `k` smaller.\\n\\nSee [Vector Index](index.md) for more information.\\n\\n#### What is the maximum vector dimension supported in Milvus?\\n\\nMilvus can manage vectors with up to 32,768 dimensions by default. You can increase the value of `Proxy.maxDimension` to allow for a larger dimension vector.\\n\\n#### Does Milvus support Apple M1 CPU?\\n\\nCurrent Milvus release does not support Apple M1 CPU.\\n\\n#### What data types does Milvus support on the primary key field?\\n\\nIn current release, Milvus supports both INT64 and string.\\n\\n#### Is Milvus scalable?\\n\\nYes. You can deploy Milvus cluster with multiple nodes via Helm Chart on Kubernetes. Refer to [Scale Guide](scaleout.md) for more instruction.\\n\\n#### Does the query perform in memory? What are incremental data and historical data?\\n\\nYes. When a query request comes, Milvus searches both incremental data and historical data by loading them into memory. Incremental data are in the growing segments, which are buffered in memory before they reach the threshold to be persisted in storage engine, while historical data are from the sealed segments that are stored in the object storage. Incremental data and historical data together constitute the whole dataset to search.\\n\\n#### Is Milvus available for concurrent search?\\n\\nYes. For queries on the same collection, Milvus concurrently searches the incremental and historical data. However, queries on different collections are conducted in series. Whereas the historical data can be an extremely huge dataset, searches on the historical data are relatively more time-consuming and essentially performed in series.\\n\\n#### Why does the data in MinIO remain after the corresponding collection is dropped?\\n\\nData in MinIO is designed to remain for a certain period of time for the convenience of data rollback.\\n\\n#### Does Milvus support message engines other than Pulsar?\\n\\nYes. Kafka is supported in Milvus 2.1.0.\\n\\n#### What's the difference between a search and a query?\\n\\nIn Milvus, a vector similarity search retrieves vectors based on similarity calculation and vector index acceleration. Unlike a vector similarity search, a vector query retrieves vectors via scalar filtering based on a boolean expression. The boolean expression filters on scalar fields or the primary key field, and it retrieves all results that match the filters. In a query, neither similarity metrics nor vector index is involved.\\n\\n#### Why does a float vector value have a precision of 7 decimal digits in Milvus?\\n\\nMilvus supports storing vectors as Float32 arrays. A Float32 value has a precision of 7 decimal digits. Even with a Float64 value, such as 1.3476964684980388, Milvus stores it as 1.347696. Therefore, when you retrieve such a vector from Milvus, the precision of the Float64 value is lost.\\n\\n#### How does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n#### Still have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. You're welcome to raise questions, share ideas, and help others.\\n- Join our [Slack community](https://slack.milvus.io/) to find support and engage with our open-source community.\\n\\n\",\n",
      "    0.8848040103912354\n",
      "  ]\n",
      "]\n",
      "================================================================================\n",
      "Original embedding-based results (top 3):\n",
      "{'id': 3, 'distance': 0.7633353471755981}\n",
      "{'id': 0, 'distance': 0.6970409154891968}\n",
      "{'id': 2, 'distance': 0.5539933443069458}\n"
     ]
    }
   ],
   "source": [
    "print('Reranked results (top 3):')\n",
    "print(json.dumps(top_reranked_docs, ensure_ascii=False, indent=2))\n",
    "\n",
    "print('================================================================================')\n",
    "print('Original embedding-based results (top 3):')\n",
    "for entry in search_res[0][:3]:\n",
    "  del entry['entity']\n",
    "  print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be478e4",
   "metadata": {},
   "source": [
    "与嵌入相似度得分相比，重排通常会显示出更高的判别得分（相关文档更接近 1.0）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215537c9",
   "metadata": {},
   "source": [
    "### 步骤 4：生成最终响应\n",
    "\n",
    "现在，让我们利用检索到的上下文生成一个综合答案：\n",
    "\n",
    "首先：将检索到的文档转换为字符串格式。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
