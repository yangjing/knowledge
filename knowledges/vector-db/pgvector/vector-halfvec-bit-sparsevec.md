# 比较 pgvector 扩展中的四种向量数据类型：`vector`, `halfvec`, `bit`, 和 `sparsevec`。

这四种类型都是为了高效地存储和查询高维数据（例如来自机器学习模型的嵌入向量），但它们在**内部表示**、**精度**、**存储空间**、**支持的操作**和**适用场景**上有显著的区别。

---

## 总结对比表

| 特性             | `vector` (标准向量)                | `halfvec` (半精度向量)            | `bit` (位向量)                         | `sparsevec` (稀疏向量)                    |
| :--------------- | :--------------------------------- | :-------------------------------- | :------------------------------------- | :---------------------------------------- |
| **内部数据类型** | 单精度浮点数 (`float4`, 32-bit)    | 半精度浮点数 (`float16`, 16-bit)  | 位 (`bit`, 1-bit)                      | 键值对 (索引：整数，值：`float4`)         |
| **存储开销**     | 高                                 | 中等                              | 极低                                   | **取决于非零值的数量**                    |
| **精度**         | **高** (单精度)                    | 中 (半精度)，可能有精度损失       | 低 (二值化)                            | 高 (单精度，仅存储有效值)                 |
| **支持的索引**   | HNSW, IVFFlat                      | HNSW, IVFFlat                     | HNSW                                   | **不支持 HNSW/IVFFlat** (但支持倒排索引)  |
| **主要操作符**   | `<->`, `<#>`, `<=>`, `cosine`      | `<->`, `<#>`, `<=>`, `cosine`     | `<->` (汉明距离)                       | `<->` (欧几里得、内积等)                  |
| **最佳适用场景** | **通用场景**，需要高精度相似性搜索 | 内存/存储敏感，可接受一定精度损失 | **二值数据**（如哈希、指纹、DNA 序列） | **超高维但稀疏**的数据（如 TF-IDF、BM25） |

---

## 详细解析

### 1. `vector` (标准向量)

这是 pgvector 最初和最常用的类型，是其他类型的基准。

- **内部表示**： 使用单精度浮点数数组 (`float4`)。
- **精度**： 高。适用于需要高保真度表示向量的场景，例如高质量的文本/图像嵌入。
- **存储空间**： 每个维度占用 4 字节。对于一个 1536 维的向量，需要 `4 * 1536 = 6144` 字节（约 6KB）。
- **操作与索引**：
  - 支持所有标准距离运算符：欧几里得距离 (`<->`)、负内积 (`<#>`)、余弦距离 (`<=>`)。
  - 支持两种高效索引：**IVFFlat** (更快创建，查询速度较快) 和 **HNSW** (更慢创建，查询速度最快、召回率最高)。
- **适用场景**： **绝大多数向量搜索场景**。当你使用 OpenAI、Cohere 等模型生成的嵌入向量时，默认应使用此类型，除非你有特殊的存储或性能限制。

### 2. `halfvec` (半精度向量)

`halfvec` 是 `vector` 的一种存储优化版本。

- **内部表示**： 使用半精度浮点数 (`float16`)。
- **精度**： 中等。半精度浮点数的表示范围和数据精度低于单精度，在计算过程中可能会引入微小的误差。对于许多相似性搜索任务，这种精度损失通常是可接受的。
- **存储空间**： 每个维度占用 2 字节。比 `vector` **节省 50% 的存储空间**。同样的 1536 维向量只需 `2 * 1536 = 3072` 字节（约 3KB）。
- **操作与索引**： 支持与 `vector` **完全相同**的操作符和索引（HNSW, IVFFlat）。
- **适用场景**：
  - 存储空间或内存带宽是主要瓶颈。
  - 你想在有限的 RAM 中容纳更大的索引。
  - 你的应用对极高的精度要求不高。
  - **注意**： 查询时，`halfvec` 值可能会被转换回 `float32` 进行计算，具体取决于 pgvector 的实现。

### 3. `bit` (位向量)

专为二值数据设计，每个维度只能是 0 或 1。

- **内部表示**： 使用位串 (`bit` string)，每个维度占 1 位。
- **精度**： 低。数据必须是二值的，丢失了所有的幅度信息。
- **存储空间**： **极其高效**。每个维度仅占 1 位。一个 1536 维的向量只需 `1536 / 8 = 192` 字节。
- **操作与索引**：
  - 主要使用 **汉明距离** (`<->`)，即计算两个位向量中不同位的数量。
  - 支持 HNSW 索引来加速汉明距离搜索。
- **适用场景**：
  - **感知哈希** (pHash)： 用于图像、视频、音频的重复或相似性检测。
  - 遗传学中的 **DNA 序列** 比对。
  - 任何原生就是二值形式的数据。

### 4. `sparsevec` (稀疏向量)

这是为了处理**稀疏高维数据**而设计的特殊类型，其中大部分维度上的值为零。

- **内部表示**： 不存储所有的零值，而是只存储**非零值及其对应的维度索引**。例如，向量 `[0, 0, 0.8, 0, 0, 0.2]` 可能被存储为 `{3:0.8, 6:0.2}`。
- **精度**： 高。非零值使用单精度浮点数 (`float4`) 存储。
- **存储空间**： **高度可变**。开销取决于非零值的数量（`K`），每个非零值需要存储一个整数索引和一个浮点数值。存储成本约为 `(4 + 4) * K` 字节。对于非常稀疏的向量（例如，10000 维中只有 100 个非零值），这比存储整个 `vector` 要小得多。
- **操作与索引**：
  - 支持欧几里得距离、内积、余弦距离等操作符 (`<->`)。
  - **关键限制**： **目前不支持 HNSW 或 IVFFlat 索引**。这是与 `vector`/`halfvec` 的最大区别。
  - 它通常依赖于**倒排索引**（每个维度记录包含该维度的向量列表）来加速查询，但 pgvector 的实现可能尚未完全优化于此。查询性能可能不如带索引的稠密向量。
- **适用场景**：
  - 来自传统信息检索领域的 **TF-IDF** 或 **BM25** 权重向量。
  - one-hot 编码或词袋模型产生的向量。
  - 任何维度极高（如数万甚至数百万）但绝大部分值都为零的向量。

## 实际应用示例

### 文本搜索系统

```sql
-- 使用Halfvec存储OpenAI嵌入（节省50%存储）
CREATE TABLE documents (
    id bigserial PRIMARY KEY,
    content text,
    embedding halfvec(1536)
);

-- 使用Sparsevec存储TF-IDF特征
CREATE TABLE documents_tfidf (
    id bigserial PRIMARY KEY,
    content text,
    embedding sparsevec(50000)  -- 5万维词汇表
);
```

### 图像相似度搜索

```sql
-- 使用Vector存储原始特征
CREATE TABLE images (
    id bigserial PRIMARY KEY,
    path text,
    features vector(2048)
);

-- 使用Bit存储图像哈希
CREATE TABLE image_hashes (
    id bigserial PRIMARY KEY,
    path text,
    hash bit(256)
);
```

### 推荐系统

```sql
-- 使用Sparsevec存储用户-物品交互
CREATE TABLE user_item_interactions (
    user_id int,
    item_id int,
    embedding sparsevec(100000),  -- 10万物品
    PRIMARY KEY (user_id, item_id)
);
```

## 总结

pgvector 的四种向量类型各有优势，选择时应考虑：

- 数据特性：密集 vs 稀疏、连续 vs 二值、维度大小
- 性能需求：查询速度、存储效率、索引构建速度
- 精度要求：是否可以接受精度损失
- 应用场景：文本、图像、推荐系统等

### 最佳实践

- **新项目优先考虑 `halfvec`**，平衡存储效率和精度。如果你的数据集非常大，并且希望减少存储成本和内存占用，可以尝试使用 `halfvec`，并评估精度损失是否在可接受范围内
- **超高维稀疏数据使用 `sparsevec`**。如果你的向量维度非常高且非常稀疏（非零值很少），例如传统的文本检索特征，使用 `sparsevec` 可以节省大量空间。但要注意，它目前缺乏类似 HNSW 的高效近似索引，在大规模数据集上做最近邻搜索可能性能不佳。
- **二值数据或哈希使用 `bit`**。如果你的数据本来就是 0/1 的位形式，并且你用汉明距离进行度量，`bit` 类型是不二之选，能极大节省空间。
- **需要最高精度且维度适中时使用 `vector`**。如果你不确定，或者你的数据是来自现代神经网络的稠密嵌入（如 OpenAI text-embedding-3），就用 `vector`。它功能最全，性能最好，支持最好的索引。

通过合理选择向量类型，可以在保证应用效果的同时，显著降低存储成本并提升查询性能。
